{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANANT TIWARI\\AppData\\Local\\Temp\\ipykernel_16068\\3226047993.py:8: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('Combined.csv')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Benign'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m y \u001b[38;5;241m=\u001b[39m output_labels[sequence_length \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m::sequence_length]  \u001b[38;5;66;03m# Selecting every nth label based on sequence length\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Ensure that input features and output labels are float32\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Check for NaN or infinite values and handle them\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Benign'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, LSTM, GRU, Dense, Bidirectional, Concatenate, Flatten, Activation, RepeatVector, Permute, Multiply\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Combined.csv')\n",
    "\n",
    "# Define the numeric features and categorical features\n",
    "numeric_features = ['Dur', 'TotPkts', 'TotBytes', 'SrcRate', 'DstRate']  # Modify if necessary\n",
    "categorical_features = ['Proto', 'State']\n",
    "\n",
    "# One-hot encoding for categorical features\n",
    "data = pd.get_dummies(data, columns=categorical_features)\n",
    "\n",
    "# Label encoding for the target column ('Label')\n",
    "label_encoder = LabelEncoder()\n",
    "data['Label'] = label_encoder.fit_transform(data['Label'])\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "data[numeric_features] = scaler.fit_transform(data[numeric_features])\n",
    "\n",
    "# Prepare the input features and target labels\n",
    "sequence_length = 10  # Sequence length for the model\n",
    "input_features = data[numeric_features + list(data.columns.difference(numeric_features + ['Label']))].values\n",
    "output_labels = data['Label'].values\n",
    "\n",
    "# Reshape input for sequence model (samples, time_steps, features)\n",
    "# Assumes data is in chronological order, otherwise sort or preprocess as needed\n",
    "X = input_features.reshape(-1, sequence_length, input_features.shape[1])\n",
    "\n",
    "# For output labels, we are predicting the last label in the sequence\n",
    "y = output_labels[sequence_length - 1::sequence_length]  # Selecting every nth label based on sequence length\n",
    "\n",
    "# Ensure that input features and output labels are float32\n",
    "X = np.array(X, dtype=np.float32)\n",
    "y = np.array(y, dtype=np.float32)\n",
    "\n",
    "# Check for NaN or infinite values and handle them\n",
    "if np.any(np.isnan(X)) or np.any(np.isinf(X)):\n",
    "    print(\"NaN or infinite values detected, replacing with 0\")\n",
    "    X = np.nan_to_num(X)  # Replace NaNs with 0 and infinite values with large numbers\n",
    "\n",
    "\n",
    "# Define the attention layer\n",
    "def attention_layer(inputs):\n",
    "    \"\"\"\n",
    "    Applies an attention mechanism on the input sequence.\n",
    "    \"\"\"\n",
    "    attention = Dense(1, activation=\"tanh\")(inputs)\n",
    "    attention = Flatten()(attention)\n",
    "    attention = Activation(\"softmax\")(attention)\n",
    "    attention = RepeatVector(inputs.shape[-1])(attention)\n",
    "    attention = Permute([2, 1])(attention)\n",
    "    \n",
    "    output_attention = Multiply()([inputs, attention])\n",
    "    return output_attention\n",
    "\n",
    "# Define model input\n",
    "input_layer = Input(shape=(sequence_length, X.shape[2]))  # (time_steps, features)\n",
    "\n",
    "# LSTM branch\n",
    "lstm_branch = LSTM(64, activation='relu', return_sequences=True)(input_layer)\n",
    "lstm_branch = LSTM(32, activation='relu', return_sequences=True)(lstm_branch)\n",
    "\n",
    "# Bidirectional LSTM branch\n",
    "bidirectional_branch = Bidirectional(LSTM(64, activation='relu', return_sequences=True))(input_layer)\n",
    "bidirectional_branch = Bidirectional(LSTM(32, activation='relu', return_sequences=True))(bidirectional_branch)\n",
    "\n",
    "# GRU branch\n",
    "gru_branch = GRU(64, activation='relu', return_sequences=True)(input_layer)\n",
    "gru_branch = GRU(32, activation='relu', return_sequences=True)(gru_branch)\n",
    "\n",
    "# Concatenate all branches\n",
    "combined = Concatenate()([lstm_branch, bidirectional_branch, gru_branch])\n",
    "\n",
    "# Apply attention mechanism\n",
    "attention_output = attention_layer(combined)\n",
    "\n",
    "# Flatten and output layers\n",
    "flattened = Flatten()(attention_output)\n",
    "dense_output = Dense(64, activation='relu')(flattened)\n",
    "dense_output = Dense(32, activation='relu')(dense_output)\n",
    "final_output = Dense(1, activation='sigmoid')(dense_output)  # Sigmoid for binary classification\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=input_layer, outputs=final_output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X, y,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,  # Automatically split 20% of the data for validation\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Input, LSTM, GRU, Dense, Bidirectional, Concatenate, Flatten, Activation, RepeatVector, Permute, Multiply\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANANT TIWARI\\AppData\\Local\\Temp\\ipykernel_16068\\3381191799.py:1: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data= pd.read_csv('Combined.csv')\n"
     ]
    }
   ],
   "source": [
    "data= pd.read_csv('Combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Seq', 'Dur', 'RunTime', 'Mean', 'Sum', 'Min', 'Max',\n",
       "       'sTos', 'dTos', 'sDSb', 'dDSb', 'sTtl', 'dTtl', 'sHops', 'dHops',\n",
       "       'Cause', 'TotPkts', 'SrcPkts', 'DstPkts', 'TotBytes', 'SrcBytes',\n",
       "       'DstBytes', 'Offset', 'sMeanPktSz', 'dMeanPktSz', 'Load', 'SrcLoad',\n",
       "       'DstLoad', 'Loss', 'SrcLoss', 'DstLoss', 'pLoss', 'SrcGap', 'DstGap',\n",
       "       'Rate', 'SrcRate', 'DstRate', 'SrcWin', 'DstWin', 'sVid', 'dVid',\n",
       "       'SrcTCPBase', 'DstTCPBase', 'TcpRtt', 'SynAck', 'AckDat', 'Label',\n",
       "       'Attack Type', 'Attack Tool', 'Proto_arp', 'Proto_icmp',\n",
       "       'Proto_ipv6-icmp', 'Proto_llc', 'Proto_lldp', 'Proto_sctp', 'Proto_tcp',\n",
       "       'Proto_udp', 'State_ACC', 'State_CON', 'State_ECO', 'State_FIN',\n",
       "       'State_INT', 'State_NRS', 'State_REQ', 'State_RSP', 'State_RST',\n",
       "       'State_TST', 'State_URP'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['sDSb', 'dDSb', 'Cause', 'Attack Type', 'Attack Tool', \n",
    "                        'Proto_arp', 'Proto_icmp', 'Proto_ipv6-icmp', 'Proto_llc', \n",
    "                        'Proto_lldp', 'Proto_sctp', 'Proto_tcp', 'Proto_udp', \n",
    "                        'State_ACC', 'State_CON', 'State_ECO', 'State_FIN', 'State_INT', \n",
    "                        'State_NRS', 'State_REQ', 'State_RSP', 'State_RST', 'State_TST', 'State_URP']\n",
    "\n",
    "# Check if all categorical features exist in the dataset\n",
    "missing_columns = [col for col in categorical_features if col not in data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing columns: ['sDSb', 'dDSb', 'Cause', 'Attack Type', 'Attack Tool']\n",
      "Index(['Unnamed: 0', 'Seq', 'Dur', 'RunTime', 'Mean', 'Sum', 'Min', 'Max',\n",
      "       'sTos', 'dTos',\n",
      "       ...\n",
      "       'State_REQ_False', 'State_REQ_True', 'State_RSP_False',\n",
      "       'State_RSP_True', 'State_RST_False', 'State_RST_True',\n",
      "       'State_TST_False', 'State_TST_True', 'State_URP_False',\n",
      "       'State_URP_True'],\n",
      "      dtype='object', length=120)\n"
     ]
    }
   ],
   "source": [
    "categorical_features = ['sDSb', 'dDSb', 'Cause', 'Attack Type', 'Attack Tool', \n",
    "                        'Proto_arp', 'Proto_icmp', 'Proto_ipv6-icmp', 'Proto_llc', \n",
    "                        'Proto_lldp', 'Proto_sctp', 'Proto_tcp', 'Proto_udp', \n",
    "                        'State_ACC', 'State_CON', 'State_ECO', 'State_FIN', 'State_INT', \n",
    "                        'State_NRS', 'State_REQ', 'State_RSP', 'State_RST', 'State_TST', 'State_URP']\n",
    "\n",
    "# Check which categorical columns are actually in the dataset\n",
    "missing_columns = [col for col in categorical_features if col not in data.columns]\n",
    "print(f\"Missing columns: {missing_columns}\")\n",
    "\n",
    "# Remove missing columns from categorical_features\n",
    "categorical_features = [col for col in categorical_features if col in data.columns]\n",
    "\n",
    "# Apply one-hot encoding only for the available categorical columns\n",
    "data = pd.get_dummies(data, columns=categorical_features)\n",
    "\n",
    "# Check the updated dataset columns\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['Dur', 'TotPkts', 'TotBytes', 'SrcRate', 'DstRate', 'RunTime', 'Mean', 'Sum', 'Min', 'Max', \n",
    "                    'sTos', 'dTos', 'sTtl', 'dTtl', 'sHops', 'dHops', 'TotPkts', 'SrcPkts', 'DstPkts', \n",
    "                    'SrcBytes', 'DstBytes', 'Offset', 'sMeanPktSz', 'dMeanPktSz', 'Load', 'SrcLoad', 'DstLoad',\n",
    "                    'Loss', 'SrcLoss', 'DstLoss', 'pLoss', 'SrcGap', 'DstGap', 'Rate', 'SrcWin', 'DstWin', \n",
    "                    'sVid', 'dVid', 'SrcTCPBase', 'DstTCPBase', 'TcpRtt', 'SynAck', 'AckDat']  # Ensure numeric columns only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['sDSb', 'dDSb', 'Cause', 'Attack Type', 'Attack Tool'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 21\u001b[0m\n\u001b[0;32m     14\u001b[0m categorical_features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msDSb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdDSb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCause\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttack Type\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttack Tool\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     15\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProto_arp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProto_icmp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProto_ipv6-icmp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProto_llc\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     16\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProto_lldp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProto_sctp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProto_tcp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProto_udp\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     17\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState_ACC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState_CON\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState_ECO\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState_FIN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState_INT\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     18\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState_NRS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState_REQ\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState_RSP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState_RST\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState_TST\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState_URP\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# One-hot encode categorical features (excluding 'Label')\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dummies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_features\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\reshape\\encoding.py:164\u001b[0m, in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput must be a list-like for parameter `columns`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 164\u001b[0m     data_to_encode \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# validate prefixes and separator to avoid silently dropping cols\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_len\u001b[39m(item, name: \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\frame.py:3902\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3901\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3902\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3904\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:6114\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6112\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6114\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6116\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6118\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:6178\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6177\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6178\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['sDSb', 'dDSb', 'Cause', 'Attack Type', 'Attack Tool'] not in index\""
     ]
    }
   ],
   "source": [
    "# numeric_features = ['Dur', 'TotPkts', 'TotBytes', 'SrcRate', 'DstRate']  # Add other relevant numeric columns\n",
    "# categorical_features = ['sDSb','dDSb','Cause','Label','Attack Type','Attack Tool']\n",
    "\n",
    "# # Encode categorical features\n",
    "# data = pd.get_dummies(data, columns=categorical_features)\n",
    "\n",
    "numeric_features = ['Dur', 'TotPkts', 'TotBytes', 'SrcRate', 'DstRate', 'RunTime', 'Mean', 'Sum', 'Min', 'Max', \n",
    "                    'sTos', 'dTos', 'sTtl', 'dTtl', 'sHops', 'dHops', 'TotPkts', 'SrcPkts', 'DstPkts', \n",
    "                    'SrcBytes', 'DstBytes', 'Offset', 'sMeanPktSz', 'dMeanPktSz', 'Load', 'SrcLoad', 'DstLoad',\n",
    "                    'Loss', 'SrcLoss', 'DstLoss', 'pLoss', 'SrcGap', 'DstGap', 'Rate', 'SrcWin', 'DstWin', \n",
    "                    'sVid', 'dVid', 'SrcTCPBase', 'DstTCPBase', 'TcpRtt', 'SynAck', 'AckDat']  # Ensure numeric columns only\n",
    "\n",
    "# Define categorical columns (excluding 'Label')\n",
    "categorical_features = ['sDSb', 'dDSb', 'Cause', 'Attack Type', 'Attack Tool', \n",
    "                        'Proto_arp', 'Proto_icmp', 'Proto_ipv6-icmp', 'Proto_llc', \n",
    "                        'Proto_lldp', 'Proto_sctp', 'Proto_tcp', 'Proto_udp', \n",
    "                        'State_ACC', 'State_CON', 'State_ECO', 'State_FIN', 'State_INT', \n",
    "                        'State_NRS', 'State_REQ', 'State_RSP', 'State_RST', 'State_TST', 'State_URP']\n",
    "\n",
    "# One-hot encode categorical features (excluding 'Label')\n",
    "data = pd.get_dummies(data, columns=categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Columns after one-hot encoding: Index(['Unnamed: 0', 'Seq', 'Dur', 'RunTime', 'Mean', 'Sum', 'Min', 'Max',\n",
      "       'sTos', 'dTos',\n",
      "       ...\n",
      "       'State_REQ_False', 'State_REQ_True', 'State_RSP_False',\n",
      "       'State_RSP_True', 'State_RST_False', 'State_RST_True',\n",
      "       'State_TST_False', 'State_TST_True', 'State_URP_False',\n",
      "       'State_URP_True'],\n",
      "      dtype='object', length=120)\n"
     ]
    }
   ],
   "source": [
    "categorical_features = ['sDSb', 'dDSb', 'Cause', 'Attack Type', 'Attack Tool', \n",
    "                        'Proto_arp', 'Proto_icmp', 'Proto_ipv6-icmp', 'Proto_llc', \n",
    "                        'Proto_lldp', 'Proto_sctp', 'Proto_tcp', 'Proto_udp', \n",
    "                        'State_ACC', 'State_CON', 'State_ECO', 'State_FIN', 'State_INT', \n",
    "                        'State_NRS', 'State_REQ', 'State_RSP', 'State_RST', 'State_TST', 'State_URP']\n",
    "\n",
    "# Remove missing columns from categorical_features\n",
    "categorical_features = [col for col in categorical_features if col in data.columns]\n",
    "\n",
    "# One-hot encode categorical features (excluding 'Label')\n",
    "data = pd.get_dummies(data, columns=categorical_features)\n",
    "\n",
    "# Verify the updated columns\n",
    "print(\"Updated Columns after one-hot encoding:\", data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0\n",
      "\n",
      "\n",
      "Seq\n",
      "\n",
      "\n",
      "Dur\n",
      "\n",
      "\n",
      "RunTime\n",
      "\n",
      "\n",
      "Mean\n",
      "\n",
      "\n",
      "Sum\n",
      "\n",
      "\n",
      "Min\n",
      "\n",
      "\n",
      "Max\n",
      "\n",
      "\n",
      "sTos\n",
      "\n",
      "\n",
      "dTos\n",
      "\n",
      "\n",
      "sTtl\n",
      "\n",
      "\n",
      "dTtl\n",
      "\n",
      "\n",
      "sHops\n",
      "\n",
      "\n",
      "dHops\n",
      "\n",
      "\n",
      "TotPkts\n",
      "\n",
      "\n",
      "SrcPkts\n",
      "\n",
      "\n",
      "DstPkts\n",
      "\n",
      "\n",
      "TotBytes\n",
      "\n",
      "\n",
      "SrcBytes\n",
      "\n",
      "\n",
      "DstBytes\n",
      "\n",
      "\n",
      "Offset\n",
      "\n",
      "\n",
      "sMeanPktSz\n",
      "\n",
      "\n",
      "dMeanPktSz\n",
      "\n",
      "\n",
      "Load\n",
      "\n",
      "\n",
      "SrcLoad\n",
      "\n",
      "\n",
      "DstLoad\n",
      "\n",
      "\n",
      "Loss\n",
      "\n",
      "\n",
      "SrcLoss\n",
      "\n",
      "\n",
      "DstLoss\n",
      "\n",
      "\n",
      "pLoss\n",
      "\n",
      "\n",
      "SrcGap\n",
      "\n",
      "\n",
      "DstGap\n",
      "\n",
      "\n",
      "Rate\n",
      "\n",
      "\n",
      "SrcRate\n",
      "\n",
      "\n",
      "DstRate\n",
      "\n",
      "\n",
      "SrcWin\n",
      "\n",
      "\n",
      "DstWin\n",
      "\n",
      "\n",
      "sVid\n",
      "\n",
      "\n",
      "dVid\n",
      "\n",
      "\n",
      "SrcTCPBase\n",
      "\n",
      "\n",
      "DstTCPBase\n",
      "\n",
      "\n",
      "TcpRtt\n",
      "\n",
      "\n",
      "SynAck\n",
      "\n",
      "\n",
      "AckDat\n",
      "\n",
      "\n",
      "sDSb_39\n",
      "\n",
      "\n",
      "sDSb_4\n",
      "\n",
      "\n",
      "sDSb_52\n",
      "\n",
      "\n",
      "sDSb_54\n",
      "\n",
      "\n",
      "sDSb_af11\n",
      "\n",
      "\n",
      "sDSb_af12\n",
      "\n",
      "\n",
      "sDSb_af41\n",
      "\n",
      "\n",
      "sDSb_cs0\n",
      "\n",
      "\n",
      "sDSb_cs4\n",
      "\n",
      "\n",
      "sDSb_cs6\n",
      "\n",
      "\n",
      "sDSb_cs7\n",
      "\n",
      "\n",
      "sDSb_ef\n",
      "\n",
      "\n",
      "dDSb_af11\n",
      "\n",
      "\n",
      "dDSb_af12\n",
      "\n",
      "\n",
      "dDSb_cs0\n",
      "\n",
      "\n",
      "dDSb_cs1\n",
      "\n",
      "\n",
      "dDSb_cs4\n",
      "\n",
      "\n",
      "dDSb_ef\n",
      "\n",
      "\n",
      "Cause_Shutdown\n",
      "\n",
      "\n",
      "Cause_Start\n",
      "\n",
      "\n",
      "Cause_Status\n",
      "\n",
      "\n",
      "Label_0\n",
      "\n",
      "\n",
      "Label_1\n",
      "\n",
      "\n",
      "Attack Type_Benign\n",
      "\n",
      "\n",
      "Attack Type_HTTPFlood\n",
      "\n",
      "\n",
      "Attack Type_ICMPFlood\n",
      "\n",
      "\n",
      "Attack Type_SYNFlood\n",
      "\n",
      "\n",
      "Attack Type_SYNScan\n",
      "\n",
      "\n",
      "Attack Type_SlowrateDoS\n",
      "\n",
      "\n",
      "Attack Type_TCPConnectScan\n",
      "\n",
      "\n",
      "Attack Type_UDPFlood\n",
      "\n",
      "\n",
      "Attack Type_UDPScan\n",
      "\n",
      "\n",
      "Attack Tool_Benign\n",
      "\n",
      "\n",
      "Attack Tool_Goldeneye\n",
      "\n",
      "\n",
      "Attack Tool_Hping3\n",
      "\n",
      "\n",
      "Attack Tool_Nmap\n",
      "\n",
      "\n",
      "Attack Tool_Slowloris\n",
      "\n",
      "\n",
      "Attack Tool_Torshammer\n",
      "\n",
      "\n",
      "Proto_arp_False\n",
      "\n",
      "\n",
      "Proto_arp_True\n",
      "\n",
      "\n",
      "Proto_icmp_False\n",
      "\n",
      "\n",
      "Proto_icmp_True\n",
      "\n",
      "\n",
      "Proto_ipv6-icmp_False\n",
      "\n",
      "\n",
      "Proto_ipv6-icmp_True\n",
      "\n",
      "\n",
      "Proto_llc_False\n",
      "\n",
      "\n",
      "Proto_llc_True\n",
      "\n",
      "\n",
      "Proto_lldp_False\n",
      "\n",
      "\n",
      "Proto_lldp_True\n",
      "\n",
      "\n",
      "Proto_sctp_False\n",
      "\n",
      "\n",
      "Proto_sctp_True\n",
      "\n",
      "\n",
      "Proto_tcp_False\n",
      "\n",
      "\n",
      "Proto_tcp_True\n",
      "\n",
      "\n",
      "Proto_udp_False\n",
      "\n",
      "\n",
      "Proto_udp_True\n",
      "\n",
      "\n",
      "State_ACC_False\n",
      "\n",
      "\n",
      "State_ACC_True\n",
      "\n",
      "\n",
      "State_CON_False\n",
      "\n",
      "\n",
      "State_CON_True\n",
      "\n",
      "\n",
      "State_ECO_False\n",
      "\n",
      "\n",
      "State_ECO_True\n",
      "\n",
      "\n",
      "State_FIN_False\n",
      "\n",
      "\n",
      "State_FIN_True\n",
      "\n",
      "\n",
      "State_INT_False\n",
      "\n",
      "\n",
      "State_INT_True\n",
      "\n",
      "\n",
      "State_NRS_False\n",
      "\n",
      "\n",
      "State_NRS_True\n",
      "\n",
      "\n",
      "State_REQ_False\n",
      "\n",
      "\n",
      "State_REQ_True\n",
      "\n",
      "\n",
      "State_RSP_False\n",
      "\n",
      "\n",
      "State_RSP_True\n",
      "\n",
      "\n",
      "State_RST_False\n",
      "\n",
      "\n",
      "State_RST_True\n",
      "\n",
      "\n",
      "State_TST_False\n",
      "\n",
      "\n",
      "State_TST_True\n",
      "\n",
      "\n",
      "State_URP_False\n",
      "\n",
      "\n",
      "State_URP_True\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data.columns)):\n",
    "    print(data.columns[i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Assuming 'Label_0' and 'Label_1' are categorical labels\n",
    "data['Label_0'] = label_encoder.fit_transform(data['Label_0'])\n",
    "data['Label_1'] = label_encoder.fit_transform(data['Label_1'])\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "data[numeric_features] = scaler.fit_transform(data[numeric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Use one of the labels for binary classification\n",
    "data['Label'] = label_encoder.fit_transform(data['Label_1'])  # Or 'Label_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output for the model\n",
    "sequence_length = 10  # Define sequence length\n",
    "input_features = data[numeric_features + list(data.columns.difference(numeric_features + ['Label_1']))].values\n",
    "output_labels = data['Label_1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Seq</th>\n",
       "      <th>Dur</th>\n",
       "      <th>RunTime</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Sum</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>sTos</th>\n",
       "      <th>dTos</th>\n",
       "      <th>...</th>\n",
       "      <th>State_REQ_True</th>\n",
       "      <th>State_RSP_False</th>\n",
       "      <th>State_RSP_True</th>\n",
       "      <th>State_RST_False</th>\n",
       "      <th>State_RST_True</th>\n",
       "      <th>State_TST_False</th>\n",
       "      <th>State_TST_True</th>\n",
       "      <th>State_URP_False</th>\n",
       "      <th>State_URP_True</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.806980</td>\n",
       "      <td>-0.806980</td>\n",
       "      <td>-0.806980</td>\n",
       "      <td>-0.806980</td>\n",
       "      <td>-0.806980</td>\n",
       "      <td>-0.806980</td>\n",
       "      <td>-0.069046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.806980</td>\n",
       "      <td>-0.806980</td>\n",
       "      <td>-0.806980</td>\n",
       "      <td>-0.806980</td>\n",
       "      <td>-0.806980</td>\n",
       "      <td>-0.806980</td>\n",
       "      <td>-0.069046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2.148165</td>\n",
       "      <td>2.148165</td>\n",
       "      <td>2.148165</td>\n",
       "      <td>2.148165</td>\n",
       "      <td>2.148165</td>\n",
       "      <td>2.148165</td>\n",
       "      <td>-0.069046</td>\n",
       "      <td>-0.125376</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2.148175</td>\n",
       "      <td>2.148175</td>\n",
       "      <td>2.148175</td>\n",
       "      <td>2.148175</td>\n",
       "      <td>2.148175</td>\n",
       "      <td>2.148175</td>\n",
       "      <td>-0.069046</td>\n",
       "      <td>-0.125376</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2.149013</td>\n",
       "      <td>2.149013</td>\n",
       "      <td>2.149013</td>\n",
       "      <td>2.149013</td>\n",
       "      <td>2.149013</td>\n",
       "      <td>2.149013</td>\n",
       "      <td>-0.069046</td>\n",
       "      <td>-0.125376</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215885</th>\n",
       "      <td>487569</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.806980</td>\n",
       "      <td>-0.806980</td>\n",
       "      <td>-0.806980</td>\n",
       "      <td>-0.806980</td>\n",
       "      <td>-0.806980</td>\n",
       "      <td>-0.806980</td>\n",
       "      <td>14.788432</td>\n",
       "      <td>8.716014</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215886</th>\n",
       "      <td>487570</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.667674</td>\n",
       "      <td>-0.667674</td>\n",
       "      <td>-0.667674</td>\n",
       "      <td>-0.667674</td>\n",
       "      <td>-0.667674</td>\n",
       "      <td>-0.667674</td>\n",
       "      <td>14.788432</td>\n",
       "      <td>1.775998</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215887</th>\n",
       "      <td>487571</td>\n",
       "      <td>764</td>\n",
       "      <td>-0.747897</td>\n",
       "      <td>-0.747897</td>\n",
       "      <td>-0.747897</td>\n",
       "      <td>-0.747897</td>\n",
       "      <td>-0.747897</td>\n",
       "      <td>-0.747897</td>\n",
       "      <td>-0.069046</td>\n",
       "      <td>-0.125376</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215888</th>\n",
       "      <td>487572</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.033695</td>\n",
       "      <td>-0.033695</td>\n",
       "      <td>-0.033695</td>\n",
       "      <td>-0.033695</td>\n",
       "      <td>-0.033695</td>\n",
       "      <td>-0.033695</td>\n",
       "      <td>14.788432</td>\n",
       "      <td>1.775998</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215889</th>\n",
       "      <td>487573</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.525064</td>\n",
       "      <td>-0.525064</td>\n",
       "      <td>-0.525064</td>\n",
       "      <td>-0.525064</td>\n",
       "      <td>-0.525064</td>\n",
       "      <td>-0.525064</td>\n",
       "      <td>14.788432</td>\n",
       "      <td>8.716014</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1215890 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  Seq       Dur   RunTime      Mean       Sum       Min  \\\n",
       "0                 0    1 -0.806980 -0.806980 -0.806980 -0.806980 -0.806980   \n",
       "1                 1    2 -0.806980 -0.806980 -0.806980 -0.806980 -0.806980   \n",
       "2                 2    3  2.148165  2.148165  2.148165  2.148165  2.148165   \n",
       "3                 3    4  2.148175  2.148175  2.148175  2.148175  2.148175   \n",
       "4                 4    5  2.149013  2.149013  2.149013  2.149013  2.149013   \n",
       "...             ...  ...       ...       ...       ...       ...       ...   \n",
       "1215885      487569    1 -0.806980 -0.806980 -0.806980 -0.806980 -0.806980   \n",
       "1215886      487570    3 -0.667674 -0.667674 -0.667674 -0.667674 -0.667674   \n",
       "1215887      487571  764 -0.747897 -0.747897 -0.747897 -0.747897 -0.747897   \n",
       "1215888      487572    3 -0.033695 -0.033695 -0.033695 -0.033695 -0.033695   \n",
       "1215889      487573    1 -0.525064 -0.525064 -0.525064 -0.525064 -0.525064   \n",
       "\n",
       "              Max       sTos      dTos  ...  State_REQ_True  State_RSP_False  \\\n",
       "0       -0.806980  -0.069046       NaN  ...           False             True   \n",
       "1       -0.806980  -0.069046       NaN  ...           False             True   \n",
       "2        2.148165  -0.069046 -0.125376  ...           False             True   \n",
       "3        2.148175  -0.069046 -0.125376  ...           False             True   \n",
       "4        2.149013  -0.069046 -0.125376  ...           False             True   \n",
       "...           ...        ...       ...  ...             ...              ...   \n",
       "1215885 -0.806980  14.788432  8.716014  ...           False             True   \n",
       "1215886 -0.667674  14.788432  1.775998  ...           False             True   \n",
       "1215887 -0.747897  -0.069046 -0.125376  ...           False             True   \n",
       "1215888 -0.033695  14.788432  1.775998  ...           False             True   \n",
       "1215889 -0.525064  14.788432  8.716014  ...           False             True   \n",
       "\n",
       "         State_RSP_True  State_RST_False  State_RST_True  State_TST_False  \\\n",
       "0                 False             True           False             True   \n",
       "1                 False             True           False             True   \n",
       "2                 False             True           False             True   \n",
       "3                 False             True           False             True   \n",
       "4                 False             True           False             True   \n",
       "...                 ...              ...             ...              ...   \n",
       "1215885           False             True           False             True   \n",
       "1215886           False             True           False             True   \n",
       "1215887           False             True           False             True   \n",
       "1215888           False             True           False             True   \n",
       "1215889           False             True           False             True   \n",
       "\n",
       "         State_TST_True  State_URP_False  State_URP_True  Label  \n",
       "0                 False             True           False      0  \n",
       "1                 False             True           False      0  \n",
       "2                 False             True           False      0  \n",
       "3                 False             True           False      0  \n",
       "4                 False             True           False      0  \n",
       "...                 ...              ...             ...    ...  \n",
       "1215885           False             True           False      0  \n",
       "1215886           False             True           False      0  \n",
       "1215887           False             True           False      0  \n",
       "1215888           False             True           False      0  \n",
       "1215889           False             True           False      0  \n",
       "\n",
       "[1215890 rows x 121 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape input for sequence model (samples, time_steps, features)\n",
    "# Assumes data is in chronological order, otherwise sort or preprocess as needed\n",
    "X = input_features.reshape(-1, sequence_length, input_features.shape[1])\n",
    "y = output_labels.reshape(-1, sequence_length)[:, -1]  # Predict based on last label in the sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN or infinite values detected, replacing with 0\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X, dtype=np.float32)\n",
    "y = np.array(y, dtype=np.float32)\n",
    "# Check for NaN or infinite values and handle them\n",
    "if np.any(np.isnan(X)) or np.any(np.isinf(X)):\n",
    "    print(\"NaN or infinite values detected, replacing with 0\")\n",
    "    X = np.nan_to_num(X)  # Replace NaNs with 0 and infinite values with large numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_layer(inputs):\n",
    "    \"\"\"\n",
    "    Applies an attention mechanism on the input sequence.\n",
    "    \"\"\"\n",
    "    attention = Dense(1, activation=\"tanh\")(inputs)\n",
    "    attention = Flatten()(attention)\n",
    "    attention = Activation(\"softmax\")(attention)\n",
    "    attention = RepeatVector(inputs.shape[-1])(attention)\n",
    "    attention = Permute([2, 1])(attention)\n",
    "    \n",
    "    output_attention = Multiply()([inputs, attention])\n",
    "    return output_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model input\n",
    "input_layer = Input(shape=(sequence_length, X.shape[2]))  # (time_steps, features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM branch\n",
    "lstm_branch = LSTM(64, activation='relu', return_sequences=True)(input_layer)\n",
    "lstm_branch = LSTM(32, activation='relu', return_sequences=True)(lstm_branch)\n",
    "\n",
    "# Bidirectional LSTM branch\n",
    "bidirectional_branch = Bidirectional(LSTM(64, activation='relu', return_sequences=True))(input_layer)\n",
    "bidirectional_branch = Bidirectional(LSTM(32, activation='relu', return_sequences=True))(bidirectional_branch)\n",
    "\n",
    "# GRU branch\n",
    "gru_branch = GRU(64, activation='relu', return_sequences=True)(input_layer)\n",
    "gru_branch = GRU(32, activation='relu', return_sequences=True)(gru_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all branches\n",
    "combined = Concatenate()([lstm_branch, bidirectional_branch, gru_branch])\n",
    "\n",
    "# Apply attention mechanism\n",
    "attention_output = attention_layer(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten and output layers\n",
    "flattened = Flatten()(attention_output)\n",
    "dense_output = Dense(64, activation='relu')(flattened)\n",
    "dense_output = Dense(32, activation='relu')(dense_output)\n",
    "final_output = Dense(1, activation='sigmoid')(dense_output)  # Sigmoid for binary classification\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=input_layer, outputs=final_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten and output layers\n",
    "flattened = Flatten()(attention_output)\n",
    "dense_output = Dense(64, activation='relu')(flattened)\n",
    "dense_output = Dense(32, activation='relu')(dense_output)\n",
    "final_output = Dense(1, activation='sigmoid')(dense_output)  # Sigmoid for binary classification\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=input_layer, outputs=final_output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display model summary\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(\n",
    "    X, y,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,  \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)        [(None, 10, 121)]            0         []                            \n",
      "                                                                                                  \n",
      " lstm_20 (LSTM)              (None, 10, 64)               47616     ['input_5[0][0]']             \n",
      "                                                                                                  \n",
      " bidirectional_10 (Bidirect  (None, 10, 128)              95232     ['input_5[0][0]']             \n",
      " ional)                                                                                           \n",
      "                                                                                                  \n",
      " gru_10 (GRU)                (None, 10, 64)               35904     ['input_5[0][0]']             \n",
      "                                                                                                  \n",
      " lstm_21 (LSTM)              (None, 10, 32)               12416     ['lstm_20[0][0]']             \n",
      "                                                                                                  \n",
      " bidirectional_11 (Bidirect  (None, 10, 64)               41216     ['bidirectional_10[0][0]']    \n",
      " ional)                                                                                           \n",
      "                                                                                                  \n",
      " gru_11 (GRU)                (None, 10, 32)               9408      ['gru_10[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate  (None, 10, 128)              0         ['lstm_21[0][0]',             \n",
      " )                                                                   'bidirectional_11[0][0]',    \n",
      "                                                                     'gru_11[0][0]']              \n",
      "                                                                                                  \n",
      " dense_16 (Dense)            (None, 10, 1)                129       ['concatenate_7[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_10 (Flatten)        (None, 10)                   0         ['dense_16[0][0]']            \n",
      "                                                                                                  \n",
      " activation_7 (Activation)   (None, 10)                   0         ['flatten_10[0][0]']          \n",
      "                                                                                                  \n",
      " repeat_vector_3 (RepeatVec  (None, 128, 10)              0         ['activation_7[0][0]']        \n",
      " tor)                                                                                             \n",
      "                                                                                                  \n",
      " permute_3 (Permute)         (None, 10, 128)              0         ['repeat_vector_3[0][0]']     \n",
      "                                                                                                  \n",
      " multiply_3 (Multiply)       (None, 10, 128)              0         ['concatenate_7[0][0]',       \n",
      "                                                                     'permute_3[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_11 (Flatten)        (None, 1280)                 0         ['multiply_3[0][0]']          \n",
      "                                                                                                  \n",
      " dense_17 (Dense)            (None, 64)                   81984     ['flatten_11[0][0]']          \n",
      "                                                                                                  \n",
      " dense_18 (Dense)            (None, 32)                   2080      ['dense_17[0][0]']            \n",
      "                                                                                                  \n",
      " dense_19 (Dense)            (None, 1)                    33        ['dense_18[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 326018 (1.24 MB)\n",
      "Trainable params: 326018 (1.24 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3040/3040 [==============================] - 91s 30ms/step - loss: 0.8764 - accuracy: 0.7701 - val_loss: 0.6342 - val_accuracy: 0.6686\n",
      "Epoch 2/50\n",
      "3040/3040 [==============================] - 81s 27ms/step - loss: 0.5194 - accuracy: 0.8062 - val_loss: 0.5769 - val_accuracy: 0.7990\n",
      "Epoch 3/50\n",
      "3040/3040 [==============================] - 83s 27ms/step - loss: 0.4540 - accuracy: 0.8308 - val_loss: 0.6725 - val_accuracy: 0.6327\n",
      "Epoch 4/50\n",
      "3040/3040 [==============================] - 149s 49ms/step - loss: 0.4218 - accuracy: 0.8430 - val_loss: 0.6122 - val_accuracy: 0.7900\n",
      "Epoch 5/50\n",
      "3040/3040 [==============================] - 79s 26ms/step - loss: 0.3265 - accuracy: 0.8580 - val_loss: 0.6607 - val_accuracy: 0.7809\n",
      "Epoch 6/50\n",
      "3040/3040 [==============================] - 80s 26ms/step - loss: 0.5874 - accuracy: 0.7503 - val_loss: 0.6426 - val_accuracy: 0.7990\n",
      "Epoch 7/50\n",
      "3040/3040 [==============================] - 82s 27ms/step - loss: 0.6850 - accuracy: 0.5593 - val_loss: 0.6236 - val_accuracy: 0.7990\n",
      "Epoch 8/50\n",
      "3040/3040 [==============================] - 83s 27ms/step - loss: 0.7051 - accuracy: 0.5598 - val_loss: 0.6319 - val_accuracy: 0.7990\n",
      "Epoch 9/50\n",
      "3040/3040 [==============================] - 83s 27ms/step - loss: 0.6851 - accuracy: 0.5596 - val_loss: 0.6299 - val_accuracy: 0.7990\n",
      "Epoch 10/50\n",
      "3040/3040 [==============================] - 82s 27ms/step - loss: 0.7288 - accuracy: 0.5595 - val_loss: 0.6188 - val_accuracy: 0.7990\n",
      "Epoch 11/50\n",
      "3040/3040 [==============================] - 84s 28ms/step - loss: 0.6925 - accuracy: 0.5594 - val_loss: 0.6174 - val_accuracy: 0.7990\n",
      "Epoch 12/50\n",
      "3040/3040 [==============================] - 80s 26ms/step - loss: 0.6913 - accuracy: 0.5594 - val_loss: 0.6441 - val_accuracy: 0.7990\n",
      "Epoch 13/50\n",
      "3040/3040 [==============================] - 81s 27ms/step - loss: 0.6953 - accuracy: 0.5594 - val_loss: 0.6206 - val_accuracy: 0.7990\n",
      "Epoch 14/50\n",
      "3040/3040 [==============================] - 82s 27ms/step - loss: 0.7144 - accuracy: 0.5595 - val_loss: 0.6281 - val_accuracy: 0.7990\n",
      "Epoch 15/50\n",
      "3040/3040 [==============================] - 80s 26ms/step - loss: 1.4544 - accuracy: 0.5595 - val_loss: 0.6280 - val_accuracy: 0.7990\n",
      "Epoch 16/50\n",
      "3040/3040 [==============================] - 80s 26ms/step - loss: 0.6953 - accuracy: 0.5596 - val_loss: 0.6245 - val_accuracy: 0.7990\n",
      "Epoch 17/50\n",
      "3040/3040 [==============================] - 81s 27ms/step - loss: 0.6866 - accuracy: 0.5596 - val_loss: 0.6354 - val_accuracy: 0.7990\n",
      "Epoch 18/50\n",
      "3040/3040 [==============================] - 80s 26ms/step - loss: 0.6895 - accuracy: 0.5595 - val_loss: 0.6173 - val_accuracy: 0.7990\n",
      "Epoch 19/50\n",
      "3040/3040 [==============================] - 82s 27ms/step - loss: 0.7204 - accuracy: 0.5596 - val_loss: 0.6272 - val_accuracy: 0.7990\n",
      "Epoch 20/50\n",
      "3040/3040 [==============================] - 82s 27ms/step - loss: 0.6968 - accuracy: 0.5595 - val_loss: 0.6319 - val_accuracy: 0.7990\n",
      "Epoch 21/50\n",
      "3040/3040 [==============================] - 82s 27ms/step - loss: 0.6904 - accuracy: 0.5596 - val_loss: 0.6128 - val_accuracy: 0.7990\n",
      "Epoch 22/50\n",
      "3040/3040 [==============================] - 80s 26ms/step - loss: 0.6893 - accuracy: 0.5595 - val_loss: 0.6221 - val_accuracy: 0.7990\n",
      "Epoch 23/50\n",
      "3040/3040 [==============================] - 83s 27ms/step - loss: 0.6879 - accuracy: 0.5595 - val_loss: 0.6367 - val_accuracy: 0.7990\n",
      "Epoch 24/50\n",
      "3040/3040 [==============================] - 81s 27ms/step - loss: 0.6862 - accuracy: 0.5596 - val_loss: 0.6402 - val_accuracy: 0.7990\n",
      "Epoch 25/50\n",
      "3040/3040 [==============================] - 89s 29ms/step - loss: 0.6866 - accuracy: 0.5596 - val_loss: 0.6428 - val_accuracy: 0.7990\n",
      "Epoch 26/50\n",
      "3040/3040 [==============================] - 80s 26ms/step - loss: 0.6864 - accuracy: 0.5595 - val_loss: 0.6431 - val_accuracy: 0.7990\n",
      "Epoch 27/50\n",
      "3040/3040 [==============================] - 79s 26ms/step - loss: 0.6862 - accuracy: 0.5596 - val_loss: 0.6183 - val_accuracy: 0.7990\n",
      "Epoch 28/50\n",
      "3040/3040 [==============================] - 78s 26ms/step - loss: 0.6862 - accuracy: 0.5595 - val_loss: 0.6250 - val_accuracy: 0.7990\n",
      "Epoch 29/50\n",
      "3040/3040 [==============================] - 78s 26ms/step - loss: 0.6894 - accuracy: 0.5596 - val_loss: 0.6195 - val_accuracy: 0.7990\n",
      "Epoch 30/50\n",
      "3040/3040 [==============================] - 80s 26ms/step - loss: 0.6862 - accuracy: 0.5595 - val_loss: 0.6345 - val_accuracy: 0.7990\n",
      "Epoch 31/50\n",
      "3040/3040 [==============================] - 79s 26ms/step - loss: 0.6862 - accuracy: 0.5595 - val_loss: 0.6303 - val_accuracy: 0.7990\n",
      "Epoch 32/50\n",
      "3040/3040 [==============================] - 78s 26ms/step - loss: 0.6862 - accuracy: 0.5595 - val_loss: 0.6321 - val_accuracy: 0.7990\n",
      "Epoch 33/50\n",
      "3040/3040 [==============================] - 119s 39ms/step - loss: 0.6863 - accuracy: 0.5595 - val_loss: 0.6167 - val_accuracy: 0.7990\n",
      "Epoch 34/50\n",
      "3040/3040 [==============================] - 108s 36ms/step - loss: 0.6862 - accuracy: 0.5595 - val_loss: 0.6323 - val_accuracy: 0.7990\n",
      "Epoch 35/50\n",
      "3040/3040 [==============================] - 113s 37ms/step - loss: 0.6862 - accuracy: 0.5595 - val_loss: 0.6399 - val_accuracy: 0.7990\n",
      "Epoch 36/50\n",
      "3040/3040 [==============================] - 73s 24ms/step - loss: 0.6862 - accuracy: 0.5595 - val_loss: 0.6205 - val_accuracy: 0.7990\n",
      "Epoch 37/50\n",
      "3040/3040 [==============================] - 72s 24ms/step - loss: 0.6862 - accuracy: 0.5595 - val_loss: 0.6282 - val_accuracy: 0.7990\n",
      "Epoch 38/50\n",
      "3040/3040 [==============================] - 86s 28ms/step - loss: 0.6893 - accuracy: 0.5595 - val_loss: 0.6150 - val_accuracy: 0.7990\n",
      "Epoch 39/50\n",
      "3040/3040 [==============================] - 113s 37ms/step - loss: 0.7220 - accuracy: 0.5596 - val_loss: 0.6236 - val_accuracy: 0.7990\n",
      "Epoch 40/50\n",
      "3040/3040 [==============================] - 102s 34ms/step - loss: 0.8415 - accuracy: 0.5595 - val_loss: 0.6356 - val_accuracy: 0.7990\n",
      "Epoch 41/50\n",
      "3040/3040 [==============================] - 117s 38ms/step - loss: 0.6861 - accuracy: 0.5595 - val_loss: 0.6252 - val_accuracy: 0.7990\n",
      "Epoch 42/50\n",
      "3040/3040 [==============================] - 130s 43ms/step - loss: 0.6861 - accuracy: 0.5595 - val_loss: 0.6342 - val_accuracy: 0.7990\n",
      "Epoch 43/50\n",
      "3040/3040 [==============================] - 118s 39ms/step - loss: 0.6865 - accuracy: 0.5595 - val_loss: 0.6306 - val_accuracy: 0.7990\n",
      "Epoch 44/50\n",
      "3040/3040 [==============================] - 108s 35ms/step - loss: 0.6867 - accuracy: 0.5596 - val_loss: 0.6287 - val_accuracy: 0.7990\n",
      "Epoch 45/50\n",
      "3040/3040 [==============================] - 125s 41ms/step - loss: 0.6861 - accuracy: 0.5596 - val_loss: 0.6444 - val_accuracy: 0.7990\n",
      "Epoch 46/50\n",
      "3040/3040 [==============================] - 114s 37ms/step - loss: 0.6861 - accuracy: 0.5596 - val_loss: 0.6202 - val_accuracy: 0.7990\n",
      "Epoch 47/50\n",
      "3040/3040 [==============================] - 107s 35ms/step - loss: 0.6862 - accuracy: 0.5596 - val_loss: 0.6312 - val_accuracy: 0.7990\n",
      "Epoch 48/50\n",
      "3040/3040 [==============================] - 115s 38ms/step - loss: 0.6861 - accuracy: 0.5596 - val_loss: 0.6381 - val_accuracy: 0.7990\n",
      "Epoch 49/50\n",
      "3040/3040 [==============================] - 117s 39ms/step - loss: 0.6861 - accuracy: 0.5596 - val_loss: 0.6345 - val_accuracy: 0.7990\n",
      "Epoch 50/50\n",
      "3040/3040 [==============================] - 123s 40ms/step - loss: 0.6861 - accuracy: 0.5596 - val_loss: 0.6201 - val_accuracy: 0.7990\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X, y,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,  \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANANT TIWARI\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('model6.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
