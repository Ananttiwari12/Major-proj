{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, GRU, Dense, RepeatVector, TimeDistributed, Concatenate, Bidirectional, Activation, Multiply\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "sequence_length = 50\n",
    "\n",
    "# Create synthetic data (example)\n",
    "df = pd.DataFrame({\n",
    "    'packet_size': np.random.normal(loc=500, scale=100, size=num_samples),\n",
    "    'connection_duration': np.random.normal(loc=2, scale=0.5, size=num_samples),\n",
    "    'packet_inter_arrival_time': np.random.normal(loc=0.02, scale=0.005, size=num_samples),\n",
    "    'SYN_packets': np.random.randint(0, 10, size=num_samples),\n",
    "    'packet_size_connection_ratio': np.random.normal(loc=250, scale=50, size=num_samples),\n",
    "    'SYN_packet_ratio': np.random.uniform(0, 1, size=num_samples)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_data: (950, 50, 6)\n",
      "Shape of y_train_data: (950, 2)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_features = scaler.fit_transform(df)\n",
    "\n",
    "# Prepare sequences\n",
    "X_train_data = []\n",
    "y_train_data = []\n",
    "\n",
    "for i in range(num_samples - sequence_length):\n",
    "    X_train_data.append(scaled_features[i:i + sequence_length])\n",
    "    # For target, take the next value after the sequence\n",
    "    y_train_data.append(scaled_features[i + sequence_length, [0, 1]])  # Changed this line\n",
    "\n",
    "X_train_data = np.array(X_train_data)\n",
    "y_train_data = np.array(y_train_data)\n",
    "\n",
    "print(\"Shape of X_train_data:\", X_train_data.shape)  # Should be (950, 50, 6)\n",
    "print(\"Shape of y_train_data:\", y_train_data.shape)  # Should be (950, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_layer(inputs):\n",
    "    \"\"\"\n",
    "    Applies an attention mechanism on the input sequence.\n",
    "    \"\"\"\n",
    "    attention = Dense(1, activation=\"tanh\")(inputs)\n",
    "    attention = Flatten()(attention)\n",
    "    attention = Activation(\"softmax\")(attention)\n",
    "    attention = RepeatVector(inputs.shape[-1])(attention)\n",
    "    attention = Permute([2, 1])(attention)\n",
    "    \n",
    "    output_attention = Multiply()([inputs, attention])\n",
    "    return output_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(sequence_length, 6))\n",
    "\n",
    "# LSTM branch\n",
    "lstm_branch = LSTM(64, activation='relu', return_sequences=True)(input_layer)\n",
    "lstm_branch = LSTM(32, activation='relu', return_sequences=True)(lstm_branch)\n",
    "\n",
    "# Bidirectional LSTM branch\n",
    "bidirectional_branch = Bidirectional(LSTM(64, activation='relu', return_sequences=True))(input_layer)\n",
    "bidirectional_branch = Bidirectional(LSTM(32, activation='relu', return_sequences=True))(bidirectional_branch)\n",
    "\n",
    "# GRU branch\n",
    "gru_branch = GRU(64, activation='relu', return_sequences=True)(input_layer)\n",
    "gru_branch = GRU(32, activation='relu', return_sequences=True)(gru_branch)\n",
    "\n",
    "# Concatenate all branches\n",
    "combined = Concatenate()([lstm_branch, bidirectional_branch, gru_branch])\n",
    "\n",
    "# Apply attention mechanism\n",
    "attention_output = attention_layer(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten and dense layers for final prediction\n",
    "x = Flatten()(attention_output)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "output_layer = Dense(2)(x)  # Predicting next packet_size and connection_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 50, 6)]              0         []                            \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 (None, 50, 64)               18176     ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " bidirectional (Bidirection  (None, 50, 128)              36352     ['input_1[0][0]']             \n",
      " al)                                                                                              \n",
      "                                                                                                  \n",
      " gru (GRU)                   (None, 50, 64)               13824     ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               (None, 50, 32)               12416     ['lstm[0][0]']                \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirecti  (None, 50, 64)               41216     ['bidirectional[0][0]']       \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " gru_1 (GRU)                 (None, 50, 32)               9408      ['gru[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 50, 128)              0         ['lstm_1[0][0]',              \n",
      "                                                                     'bidirectional_1[0][0]',     \n",
      "                                                                     'gru_1[0][0]']               \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 50, 1)                129       ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 50)                   0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, 50)                   0         ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " repeat_vector (RepeatVecto  (None, 128, 50)              0         ['activation[0][0]']          \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " permute (Permute)           (None, 50, 128)              0         ['repeat_vector[0][0]']       \n",
      "                                                                                                  \n",
      " multiply (Multiply)         (None, 50, 128)              0         ['concatenate[0][0]',         \n",
      "                                                                     'permute[0][0]']             \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 6400)                 0         ['multiply[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 128)                  819328    ['flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 64)                   8256      ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 2)                    130       ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 959235 (3.66 MB)\n",
      "Trainable params: 959235 (3.66 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build and compile the model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "24/24 [==============================] - 2s 100ms/step - loss: 0.0236 - mae: 0.1215 - val_loss: 0.0232 - val_mae: 0.1199\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 2s 104ms/step - loss: 0.0233 - mae: 0.1200 - val_loss: 0.0231 - val_mae: 0.1184\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 3s 115ms/step - loss: 0.0236 - mae: 0.1212 - val_loss: 0.0238 - val_mae: 0.1203\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 3s 114ms/step - loss: 0.0236 - mae: 0.1209 - val_loss: 0.0237 - val_mae: 0.1204\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 3s 133ms/step - loss: 0.0232 - mae: 0.1202 - val_loss: 0.0227 - val_mae: 0.1179\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 3s 126ms/step - loss: 0.0232 - mae: 0.1205 - val_loss: 0.0243 - val_mae: 0.1218\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 3s 128ms/step - loss: 0.0231 - mae: 0.1200 - val_loss: 0.0228 - val_mae: 0.1180\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 3s 125ms/step - loss: 0.0232 - mae: 0.1199 - val_loss: 0.0233 - val_mae: 0.1188\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 3s 117ms/step - loss: 0.0233 - mae: 0.1200 - val_loss: 0.0229 - val_mae: 0.1179\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 3s 119ms/step - loss: 0.0233 - mae: 0.1203 - val_loss: 0.0237 - val_mae: 0.1198\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 3s 119ms/step - loss: 0.0235 - mae: 0.1212 - val_loss: 0.0244 - val_mae: 0.1216\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 3s 116ms/step - loss: 0.0231 - mae: 0.1200 - val_loss: 0.0247 - val_mae: 0.1229\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 3s 122ms/step - loss: 0.0235 - mae: 0.1212 - val_loss: 0.0231 - val_mae: 0.1187\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 3s 123ms/step - loss: 0.0234 - mae: 0.1207 - val_loss: 0.0238 - val_mae: 0.1201\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 3s 116ms/step - loss: 0.0229 - mae: 0.1192 - val_loss: 0.0235 - val_mae: 0.1193\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 3s 123ms/step - loss: 0.0230 - mae: 0.1197 - val_loss: 0.0228 - val_mae: 0.1182\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 3s 124ms/step - loss: 0.0232 - mae: 0.1204 - val_loss: 0.0228 - val_mae: 0.1184\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 3s 121ms/step - loss: 0.0231 - mae: 0.1196 - val_loss: 0.0242 - val_mae: 0.1212\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 3s 119ms/step - loss: 0.0232 - mae: 0.1202 - val_loss: 0.0235 - val_mae: 0.1192\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 3s 128ms/step - loss: 0.0228 - mae: 0.1195 - val_loss: 0.0229 - val_mae: 0.1186\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 3s 114ms/step - loss: 0.0232 - mae: 0.1205 - val_loss: 0.0228 - val_mae: 0.1180\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 3s 115ms/step - loss: 0.0229 - mae: 0.1195 - val_loss: 0.0239 - val_mae: 0.1208\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 3s 118ms/step - loss: 0.0226 - mae: 0.1189 - val_loss: 0.0231 - val_mae: 0.1189\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 3s 120ms/step - loss: 0.0223 - mae: 0.1181 - val_loss: 0.0235 - val_mae: 0.1195\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 3s 112ms/step - loss: 0.0223 - mae: 0.1185 - val_loss: 0.0248 - val_mae: 0.1227\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 3s 118ms/step - loss: 0.0230 - mae: 0.1206 - val_loss: 0.0239 - val_mae: 0.1215\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 3s 114ms/step - loss: 0.0228 - mae: 0.1198 - val_loss: 0.0236 - val_mae: 0.1209\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 3s 116ms/step - loss: 0.0217 - mae: 0.1167 - val_loss: 0.0237 - val_mae: 0.1202\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 3s 112ms/step - loss: 0.0212 - mae: 0.1151 - val_loss: 0.0243 - val_mae: 0.1219\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 3s 112ms/step - loss: 0.0213 - mae: 0.1158 - val_loss: 0.0244 - val_mae: 0.1221\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 3s 116ms/step - loss: 0.0208 - mae: 0.1139 - val_loss: 0.0243 - val_mae: 0.1221\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 3s 113ms/step - loss: 0.0206 - mae: 0.1138 - val_loss: 0.0254 - val_mae: 0.1246\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 3s 113ms/step - loss: 0.0208 - mae: 0.1146 - val_loss: 0.0244 - val_mae: 0.1227\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 3s 118ms/step - loss: 0.0205 - mae: 0.1132 - val_loss: 0.0255 - val_mae: 0.1249\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 3s 116ms/step - loss: 0.0200 - mae: 0.1125 - val_loss: 0.0249 - val_mae: 0.1241\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 3s 109ms/step - loss: 0.0199 - mae: 0.1116 - val_loss: 0.0254 - val_mae: 0.1251\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 3s 127ms/step - loss: 0.0194 - mae: 0.1107 - val_loss: 0.0252 - val_mae: 0.1250\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 3s 120ms/step - loss: 0.0197 - mae: 0.1113 - val_loss: 0.0257 - val_mae: 0.1259\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 3s 115ms/step - loss: 0.0190 - mae: 0.1098 - val_loss: 0.0264 - val_mae: 0.1281\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 3s 111ms/step - loss: 0.0187 - mae: 0.1085 - val_loss: 0.0273 - val_mae: 0.1304\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 3s 107ms/step - loss: 0.0189 - mae: 0.1090 - val_loss: 0.0260 - val_mae: 0.1272\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 3s 114ms/step - loss: 0.0183 - mae: 0.1071 - val_loss: 0.0271 - val_mae: 0.1306\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 3s 110ms/step - loss: 0.0179 - mae: 0.1065 - val_loss: 0.0280 - val_mae: 0.1326\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 3s 118ms/step - loss: 0.0174 - mae: 0.1048 - val_loss: 0.0270 - val_mae: 0.1294\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 3s 112ms/step - loss: 0.0170 - mae: 0.1034 - val_loss: 0.0283 - val_mae: 0.1337\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 3s 110ms/step - loss: 0.0175 - mae: 0.1046 - val_loss: 0.0268 - val_mae: 0.1293\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 3s 112ms/step - loss: 0.0171 - mae: 0.1035 - val_loss: 0.0267 - val_mae: 0.1297\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 3s 111ms/step - loss: 0.0164 - mae: 0.1018 - val_loss: 0.0278 - val_mae: 0.1320\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 3s 115ms/step - loss: 0.0158 - mae: 0.1000 - val_loss: 0.0291 - val_mae: 0.1351\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 3s 138ms/step - loss: 0.0155 - mae: 0.0986 - val_loss: 0.0290 - val_mae: 0.1353\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_data, \n",
    "    y_train_data,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANANT TIWARI\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('model4.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
