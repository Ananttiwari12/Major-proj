{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkAnomalyDetector:\n",
    "    def __init__(self, sequence_length=10):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.scaler = StandardScaler()\n",
    "        self.model = None\n",
    "        self.feature_columns = None\n",
    "        \n",
    "    def prepare_sequences(self, data):\n",
    "        \"\"\"Create sequences for LSTM input\"\"\"\n",
    "        sequences = []\n",
    "        labels = []\n",
    "        \n",
    "        for i in range(len(data) - self.sequence_length):\n",
    "            sequences.append(data[i:(i + self.sequence_length)])\n",
    "            labels.append(data.iloc[i + self.sequence_length]['Anomaly'])\n",
    "            \n",
    "        return np.array(sequences), np.array(labels)\n",
    "    \n",
    "    def preprocess_data(self, df):\n",
    "        \"\"\"Preprocess the data and create sequences\"\"\"\n",
    "        # Select numerical features only\n",
    "        numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "        self.feature_columns = [col for col in numerical_columns if col != 'Anomaly']\n",
    "        \n",
    "        # Scale the features\n",
    "        scaled_data = pd.DataFrame(\n",
    "            self.scaler.fit_transform(df[self.feature_columns]),\n",
    "            columns=self.feature_columns\n",
    "        )\n",
    "        scaled_data['Anomaly'] = df['Anomaly']\n",
    "        \n",
    "        # Create sequences\n",
    "        X, y = self.prepare_sequences(scaled_data)\n",
    "        return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    def build_model(self, input_shape):\n",
    "        \"\"\"Build LSTM model\"\"\"\n",
    "        model = Sequential([\n",
    "            LSTM(64, activation='relu', input_shape=input_shape, return_sequences=True),\n",
    "            Dropout(0.2),\n",
    "            LSTM(32, activation='relu'),\n",
    "            Dropout(0.2),\n",
    "            Dense(16, activation='relu'),\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    "        )\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        self.model = model\n",
    "        return model\n",
    "    \n",
    "    def train(self, df, epochs=50, batch_size=32):\n",
    "        \"\"\"Train the model\"\"\"\n",
    "        # Preprocess data\n",
    "        X_train, X_test, y_train, y_test = self.preprocess_data(df)\n",
    "        \n",
    "        # Build model if not already built\n",
    "        if self.model is None:\n",
    "            self.build_model((X_train.shape[1], X_train.shape[2]))\n",
    "        \n",
    "        # Train model\n",
    "        history = self.model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_test, y_test),\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        self.model.save('model7.h5')\n",
    "        \n",
    "        return history, (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "detector = NetworkAnomalyDetector(sequence_length=10)\n",
    "df= pd.read_csv(\"New_dataset2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 10, 64)            25088     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 10, 64)            0         \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38049 (148.63 KB)\n",
      "Trainable params: 38049 (148.63 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "250/250 [==============================] - 5s 11ms/step - loss: 0.2181 - accuracy: 0.9492 - auc: 0.5211 - val_loss: 0.2392 - val_accuracy: 0.9409 - val_auc: 0.4666\n",
      "Epoch 2/30\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.1953 - accuracy: 0.9522 - auc: 0.5473 - val_loss: 0.2266 - val_accuracy: 0.9409 - val_auc: 0.5075\n",
      "Epoch 3/30\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.1927 - accuracy: 0.9522 - auc: 0.5826 - val_loss: 0.2278 - val_accuracy: 0.9409 - val_auc: 0.5001\n",
      "Epoch 4/30\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.1899 - accuracy: 0.9522 - auc: 0.6151 - val_loss: 0.2417 - val_accuracy: 0.9409 - val_auc: 0.5035\n",
      "Epoch 5/30\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.1836 - accuracy: 0.9522 - auc: 0.6763 - val_loss: 0.3010 - val_accuracy: 0.9409 - val_auc: 0.4756\n",
      "Epoch 6/30\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.1779 - accuracy: 0.9522 - auc: 0.7207 - val_loss: 0.2384 - val_accuracy: 0.9409 - val_auc: 0.5103\n",
      "Epoch 7/30\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.1658 - accuracy: 0.9522 - auc: 0.7857 - val_loss: 0.2772 - val_accuracy: 0.9409 - val_auc: 0.5247\n",
      "Epoch 8/30\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.1544 - accuracy: 0.9522 - auc: 0.8379 - val_loss: 0.3563 - val_accuracy: 0.9409 - val_auc: 0.5304\n",
      "Epoch 9/30\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.1433 - accuracy: 0.9522 - auc: 0.8727 - val_loss: 0.3880 - val_accuracy: 0.9409 - val_auc: 0.5353\n",
      "Epoch 10/30\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.1282 - accuracy: 0.9525 - auc: 0.9107 - val_loss: 0.4755 - val_accuracy: 0.9409 - val_auc: 0.5297\n",
      "Epoch 11/30\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.1168 - accuracy: 0.9537 - auc: 0.9288 - val_loss: 0.4630 - val_accuracy: 0.9379 - val_auc: 0.5542\n",
      "Epoch 12/30\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.1027 - accuracy: 0.9562 - auc: 0.9500 - val_loss: 0.5230 - val_accuracy: 0.9309 - val_auc: 0.5315\n",
      "Epoch 13/30\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 0.0939 - accuracy: 0.9572 - auc: 0.9618 - val_loss: 0.7614 - val_accuracy: 0.9199 - val_auc: 0.5455\n",
      "Epoch 14/30\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.0833 - accuracy: 0.9625 - auc: 0.9689 - val_loss: 1.0032 - val_accuracy: 0.9304 - val_auc: 0.5297\n",
      "Epoch 15/30\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.0732 - accuracy: 0.9642 - auc: 0.9772 - val_loss: 1.5108 - val_accuracy: 0.9139 - val_auc: 0.5372\n",
      "Epoch 16/30\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.0620 - accuracy: 0.9745 - auc: 0.9837 - val_loss: 1.4480 - val_accuracy: 0.9214 - val_auc: 0.5081\n",
      "Epoch 17/30\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 0.0560 - accuracy: 0.9760 - auc: 0.9872 - val_loss: 1.3014 - val_accuracy: 0.9124 - val_auc: 0.5412\n",
      "Epoch 18/30\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.0508 - accuracy: 0.9775 - auc: 0.9912 - val_loss: 1.4212 - val_accuracy: 0.9164 - val_auc: 0.5385\n",
      "Epoch 19/30\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.0434 - accuracy: 0.9826 - auc: 0.9925 - val_loss: 3.1036 - val_accuracy: 0.9284 - val_auc: 0.5247\n",
      "Epoch 20/30\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.0386 - accuracy: 0.9839 - auc: 0.9948 - val_loss: 2.9646 - val_accuracy: 0.9094 - val_auc: 0.5226\n",
      "Epoch 21/30\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.0417 - accuracy: 0.9842 - auc: 0.9908 - val_loss: 2.0317 - val_accuracy: 0.9124 - val_auc: 0.5477\n",
      "Epoch 22/30\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.0327 - accuracy: 0.9877 - auc: 0.9942 - val_loss: 2.1336 - val_accuracy: 0.9214 - val_auc: 0.5384\n",
      "Epoch 23/30\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.0311 - accuracy: 0.9880 - auc: 0.9943 - val_loss: 2.1465 - val_accuracy: 0.9124 - val_auc: 0.5437\n",
      "Epoch 24/30\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.0279 - accuracy: 0.9895 - auc: 0.9974 - val_loss: 2.1734 - val_accuracy: 0.9114 - val_auc: 0.5413\n",
      "Epoch 25/30\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.0276 - accuracy: 0.9910 - auc: 0.9963 - val_loss: 2.4421 - val_accuracy: 0.9294 - val_auc: 0.5111\n",
      "Epoch 26/30\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.0222 - accuracy: 0.9922 - auc: 0.9983 - val_loss: 2.8811 - val_accuracy: 0.9194 - val_auc: 0.5427\n",
      "Epoch 27/30\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.0210 - accuracy: 0.9926 - auc: 0.9973 - val_loss: 2.8718 - val_accuracy: 0.9199 - val_auc: 0.5229\n",
      "Epoch 28/30\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.0237 - accuracy: 0.9920 - auc: 0.9968 - val_loss: 3.4960 - val_accuracy: 0.9274 - val_auc: 0.5227\n",
      "Epoch 29/30\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.0151 - accuracy: 0.9947 - auc: 0.9967 - val_loss: 4.3097 - val_accuracy: 0.9304 - val_auc: 0.5345\n",
      "Epoch 30/30\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 0.0229 - accuracy: 0.9921 - auc: 0.9957 - val_loss: 3.2337 - val_accuracy: 0.9224 - val_auc: 0.5445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANANT TIWARI\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history, (X_test, y_test) = detector.train(df, epochs=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
